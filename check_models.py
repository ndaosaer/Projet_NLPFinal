"""
check_models.py
Script de diagnostic pour v√©rifier la pr√©sence de tous les fichiers n√©cessaires
√Ä ex√©cuter depuis le dossier racine du projet
"""

from pathlib import Path
import pickle
import sys

def check_structure():
    """V√©rifier la structure du projet"""
    print("\n" + "="*70)
    print("üîç DIAGNOSTIC DE LA STRUCTURE DU PROJET")
    print("="*70 + "\n")
    
    # D√©terminer le r√©pertoire du projet
    current_dir = Path.cwd()
    print(f"üìÅ R√©pertoire actuel: {current_dir}\n")
    
    # V√©rifier les dossiers principaux
    folders_to_check = {
        "api": "Dossier de l'API",
        "models_saved": "Dossier des mod√®les sauvegard√©s",
        "src": "Dossier du code source",
        "data": "Dossier des donn√©es",
        "notebooks": "Dossier des notebooks"
    }
    
    print("üìÇ STRUCTURE DES DOSSIERS:")
    print("-" * 70)
    all_folders_ok = True
    for folder, description in folders_to_check.items():
        folder_path = current_dir / folder
        exists = folder_path.exists()
        status = "‚úÖ" if exists else "‚ùå"
        print(f"{status} {folder:20s} - {description}")
        if not exists:
            all_folders_ok = False
    
    print("\n" + "="*70)
    
    # V√©rifier les fichiers de mod√®les
    print("\nü§ñ FICHIERS DE MOD√àLES:")
    print("-" * 70)
    
    models_dir = current_dir / "models_saved"
    
    if not models_dir.exists():
        print(f"‚ùå Le dossier {models_dir} n'existe pas!")
        print("   Vous devez d'abord ex√©cuter le notebook 04_modeling.ipynb")
        return False
    
    # Fichiers essentiels
    essential_files = {
        "tfidf_vectorizer.pkl": "Vectorizer TF-IDF (cr√©√© par 03_feature_extraction.ipynb)",
        "label_encoder.pkl": "Encodeur de labels (cr√©√© par 04_modeling.ipynb)",
    }
    
    # Fichiers de mod√®les possibles
    model_files = [
        "best_model.pkl",
        "Random_Forest_model.pkl",
        "Logistic_Regression_model.pkl",
        "SVM_model.pkl",
        "Naive_Bayes_model.pkl"
    ]
    
    all_files_ok = True
    
    # V√©rifier les fichiers essentiels
    for filename, description in essential_files.items():
        filepath = models_dir / filename
        exists = filepath.exists()
        status = "‚úÖ" if exists else "‚ùå"
        print(f"{status} {filename:30s} - {description}")
        if exists:
            size = filepath.stat().st_size / 1024  # Taille en KB
            print(f"     Taille: {size:.1f} KB")
        if not exists:
            all_files_ok = False
    
    # V√©rifier au moins un fichier de mod√®le
    print(f"\nüéØ MOD√àLES ML DISPONIBLES:")
    model_found = False
    for model_file in model_files:
        filepath = models_dir / model_file
        if filepath.exists():
            size = filepath.stat().st_size / 1024
            print(f"‚úÖ {model_file:30s} - Taille: {size:.1f} KB")
            model_found = True
    
    if not model_found:
        print(f"‚ùå Aucun mod√®le ML trouv√©!")
        print(f"   Noms recherch√©s: {', '.join(model_files)}")
        all_files_ok = False
    
    # Lister tous les fichiers pr√©sents
    print(f"\nüìã TOUS LES FICHIERS DANS {models_dir}:")
    print("-" * 70)
    if list(models_dir.iterdir()):
        for file in sorted(models_dir.iterdir()):
            if file.is_file():
                size = file.stat().st_size / 1024
                print(f"   - {file.name:40s} ({size:.1f} KB)")
    else:
        print("   (Dossier vide)")
    
    # V√©rifier src/preprocessing/text_cleaner.py
    print(f"\nüìÑ FICHIERS DE CODE SOURCE:")
    print("-" * 70)
    
    text_cleaner_path = current_dir / "src" / "preprocessing" / "text_cleaner.py"
    exists = text_cleaner_path.exists()
    status = "‚úÖ" if exists else "‚ùå"
    print(f"{status} src/preprocessing/text_cleaner.py")
    if not exists:
        print("   ‚ö†Ô∏è  Ce fichier est n√©cessaire pour le nettoyage du texte")
        all_files_ok = False
    
    # V√©rifier api/main.py
    api_main_path = current_dir / "api" / "main.py"
    exists = api_main_path.exists()
    status = "‚úÖ" if exists else "‚ùå"
    print(f"{status} api/main.py")
    
    print("\n" + "="*70)
    
    # R√©sum√© final
    print("\nüìä R√âSUM√â:")
    print("-" * 70)
    
    if all_folders_ok and all_files_ok and model_found:
        print("‚úÖ ‚úÖ ‚úÖ  TOUT EST PR√äT!")
        print("\nüìå PROCHAINES √âTAPES:")
        print("   1. D√©marrer l'API:")
        print("      cd api")
        print("      python main.py")
        print("      OU")
        print("      uvicorn main:app --reload --port 8000")
        print("\n   2. Tester l'API:")
        print("      http://localhost:8000/docs")
        return True
    else:
        print("‚ùå ‚ùå ‚ùå  DES FICHIERS SONT MANQUANTS!")
        print("\nüìå ACTIONS √Ä EFFECTUER:")
        
        if not model_found:
            print("   1. Ex√©cutez le notebook: notebooks/04_modeling.ipynb")
            print("      ‚Üí Cela cr√©era les fichiers de mod√®les")
        
        if not (models_dir / "tfidf_vectorizer.pkl").exists():
            print("   2. Ex√©cutez le notebook: notebooks/03_feature_extraction.ipynb")
            print("      ‚Üí Cela cr√©era le vectorizer TF-IDF")
        
        if not text_cleaner_path.exists():
            print("   3. V√©rifiez que le fichier src/preprocessing/text_cleaner.py existe")
            print("      ‚Üí Cr√©ez-le si n√©cessaire")
        
        return False


def test_model_loading():
    """Tester le chargement des mod√®les"""
    print("\n" + "="*70)
    print("üß™ TEST DE CHARGEMENT DES MOD√àLES")
    print("="*70 + "\n")
    
    current_dir = Path.cwd()
    models_dir = current_dir / "models_saved"
    
    # Tester le chargement du vectorizer
    vectorizer_path = models_dir / "tfidf_vectorizer.pkl"
    if vectorizer_path.exists():
        try:
            with open(vectorizer_path, 'rb') as f:
                vectorizer = pickle.load(f)
            print(f"‚úÖ Vectorizer charg√© avec succ√®s")
            print(f"   Type: {type(vectorizer).__name__}")
            if hasattr(vectorizer, 'max_features'):
                print(f"   Max features: {vectorizer.max_features}")
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement du vectorizer: {e}")
    
    # Tester le chargement du label encoder
    encoder_path = models_dir / "label_encoder.pkl"
    if encoder_path.exists():
        try:
            with open(encoder_path, 'rb') as f:
                label_encoder = pickle.load(f)
            print(f"‚úÖ Label Encoder charg√© avec succ√®s")
            print(f"   Nombre de cat√©gories: {len(label_encoder.classes_)}")
            print(f"   Cat√©gories: {', '.join(label_encoder.classes_[:5])}...")
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement du label encoder: {e}")
    
    # Tester le chargement d'un mod√®le
    model_files = ["best_model.pkl", "Random_Forest_model.pkl"]
    for model_file in model_files:
        model_path = models_dir / model_file
        if model_path.exists():
            try:
                with open(model_path, 'rb') as f:
                    model = pickle.load(f)
                print(f"‚úÖ Mod√®le {model_file} charg√© avec succ√®s")
                print(f"   Type: {type(model).__name__}")
                break
            except Exception as e:
                print(f"‚ùå Erreur lors du chargement du mod√®le {model_file}: {e}")


if __name__ == "__main__":
    print("\n" + "="*70)
    print("üîß OUTIL DE DIAGNOSTIC - PROJET CV CLASSIFICATION")
    print("="*70)
    
    # V√©rifier la structure
    structure_ok = check_structure()
    
    # Si la structure est OK, tester le chargement
    if structure_ok:
        test_model_loading()
    
    print("\n" + "="*70)
    print("‚ú® DIAGNOSTIC TERMIN√â")
    print("="*70 + "\n")
